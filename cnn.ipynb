{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\"トレーニングデータの読み込み\"\"\"\n",
    "# 長さ128(2.56sec)のトレーニングデータが7521件/21人分\n",
    "acc_x_train_df=pd.read_csv('./UCI HAR Dataset/train/Inertial Signals/total_acc_x_train.txt', header=None, sep='\\s+', na_values='na')\n",
    "acc_y_train_df=pd.read_csv('./UCI HAR Dataset/train/Inertial Signals/total_acc_y_train.txt', header=None, sep='\\s+', na_values='na')\n",
    "acc_z_train_df=pd.read_csv('./UCI HAR Dataset/train/Inertial Signals/total_acc_z_train.txt', header=None, sep='\\s+', na_values='na')\n",
    "\n",
    "# Dataframeからarrayへ変換\n",
    "acc_x_train=acc_x_train_df.values\n",
    "acc_y_train=acc_y_train_df.values\n",
    "acc_z_train=acc_z_train_df.values\n",
    "\n",
    "# 3軸を横に並べる\n",
    "X_train=np.c_[acc_x_train, acc_y_train, acc_z_train]\n",
    "\n",
    "# 正解ラベル\n",
    "    # 1 WALKING\n",
    "    # 2 WALKING_UPSTAIRS\n",
    "    # 3 WALKING_DOWNSTAIRS\n",
    "    # 4 SITTING\n",
    "    # 5 STANDING\n",
    "    # 6 LAYING\n",
    "train_label_df=pd.read_csv('./UCI HAR Dataset/train/Inertial Signals/y_train.txt', header=None, sep='\\s+', na_values='na')\n",
    "y_train=train_label_df.values.reshape(-1)\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "# 正解ラベルをone hot表現にする\n",
    "#ohe = OneHotEncoder()\n",
    "#y_train = ohe.fit_transform(train_label).A \n",
    "\n",
    "\"\"\"トレーニングデータの読み込み\"\"\"\n",
    "# 長さ128(2.56sec)のトレーニングデータが7521件/21人分\n",
    "acc_x_test_df=pd.read_csv('./UCI HAR Dataset/test/Inertial Signals/total_acc_x_test.txt', header=None, sep='\\s+', na_values='na')\n",
    "acc_y_test_df=pd.read_csv('./UCI HAR Dataset/test/Inertial Signals/total_acc_y_test.txt', header=None, sep='\\s+', na_values='na')\n",
    "acc_z_test_df=pd.read_csv('./UCI HAR Dataset/test/Inertial Signals/total_acc_z_test.txt', header=None, sep='\\s+', na_values='na')\n",
    "\n",
    "# Dataframeからarrayへ変換\n",
    "acc_x_test=acc_x_test_df.values\n",
    "acc_y_test=acc_y_test_df.values\n",
    "acc_z_test=acc_z_test_df.values\n",
    "\n",
    "# 3軸を横に並べる\n",
    "X_test=np.c_[acc_x_test, acc_y_test, acc_z_test]\n",
    "\n",
    "# 正解ラベル\n",
    "    # 1 WALKING\n",
    "    # 2 WALKING_UPSTAIRS\n",
    "    # 3 WALKING_DOWNSTAIRS\n",
    "    # 4 SITTING\n",
    "    # 5 STANDING\n",
    "    # 6 LAYING\n",
    "test_label_df=pd.read_csv('./UCI HAR Dataset/test/Inertial Signals/y_test.txt', header=None, sep='\\s+', na_values='na')\n",
    "y_test=test_label_df.values.reshape(-1)\n",
    "le = LabelEncoder()\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    " \n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__() # nn.Moduleを継承する\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=18, kernel_size=(2,12)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.BatchNorm2d(18)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=18, out_channels=36, kernel_size=(1,12)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.BatchNorm2d(36)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=36, out_channels=24, kernel_size=(1,12)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.BatchNorm2d(24)\n",
    "        )\n",
    "        self.full_connection = nn.Sequential(\n",
    "            nn.Linear(in_features=6*2*24, out_features=1024), # in_featuresは直前の出力ユニット数\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=1024, out_features=num_classes)\n",
    "        )\n",
    " \n",
    " \n",
    "    # Forward計算の定義\n",
    "    # 参考：Define by Runの特徴（入力に合わせてForward計算を変更可）\n",
    "    def forward(self, x):\n",
    " \n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    " \n",
    "        # 直前のMaxPoolの出力が2次元（×チャネル数）なので，全結合の入力形式に変換\n",
    "        # 参考：KerasのFlatten()と同じような処理\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = self.full_connection(x)\n",
    "        \n",
    "        return y\n",
    " \n",
    " \n",
    "# 学習用関数\n",
    "def train(loader_train, model_obj, optimizer, loss_fn, device, total_epoch, epoch):\n",
    "    \n",
    "    model_obj.train() # モデルを学習モードに変更\n",
    " \n",
    "    # ミニバッチごとに学習\n",
    "    for data, targets in loader_train:\n",
    " \n",
    "        data = data.to(device) # GPUを使用するため，to()で明示的に指定\n",
    "        targets = targets.to(device) # 同上\n",
    " \n",
    "        optimizer.zero_grad() # 勾配を初期化\n",
    "        outputs = model_obj(data) # 順伝播の計算\n",
    "        loss = loss_fn(outputs, targets) # 誤差を計算\n",
    "        loss.backward() # 誤差を逆伝播させる\n",
    "        optimizer.step() # 重みを更新する\n",
    "    \n",
    "    print ('Epoch [%d/%d], Loss: %.4f' % (epoch, total_epoch, loss.item()))\n",
    " \n",
    " \n",
    "# テスト用関数\n",
    "def test(loader_test, trained_model, device):\n",
    " \n",
    "    trained_model.eval() # モデルを推論モードに変更\n",
    "    correct = 0 # 正解率計算用の変数を宣言\n",
    " \n",
    "    # ミニバッチごとに推論\n",
    "    with torch.no_grad(): # 推論時には勾配は不要\n",
    "        for data, targets in loader_test:\n",
    " \n",
    "            data = data.to(device) #  GPUを使用するため，to()で明示的に指定\n",
    "            targets = targets.to(device) # 同上\n",
    " \n",
    "            outputs = trained_model(data) # 順伝播の計算\n",
    " \n",
    "            # 推論結果の取得と正誤判定\n",
    "            _, predicted = torch.max(outputs.data, 1) # 確率が最大のラベルを取得\n",
    "            correct += predicted.eq(targets.data.view_as(predicted)).sum() # 正解ならば正解数をカウントアップ\n",
    "    \n",
    "    # 正解率を計算\n",
    "    data_num = len(loader_test.dataset) # テストデータの総数\n",
    "    print('\\nAccuracy: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "CNN(\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(1, 18, kernel_size=(2, 12), stride=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(18, 36, kernel_size=(1, 12), stride=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Conv2d(36, 24, kernel_size=(1, 12), stride=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (full_connection): Sequential(\n",
      "    (0): Linear(in_features=288, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=1024, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "Begin train\n",
      "Epoch [1/400], Loss: 0.2567\n",
      "\n",
      "Accuracy: 1596/2947 (54%)\n",
      "\n",
      "Epoch [2/400], Loss: 0.4094\n",
      "\n",
      "Accuracy: 2094/2947 (71%)\n",
      "\n",
      "Epoch [3/400], Loss: 0.1537\n",
      "\n",
      "Accuracy: 2413/2947 (81%)\n",
      "\n",
      "Epoch [4/400], Loss: 0.1595\n",
      "\n",
      "Accuracy: 2498/2947 (84%)\n",
      "\n",
      "Epoch [5/400], Loss: 0.1831\n",
      "\n",
      "Accuracy: 2585/2947 (87%)\n",
      "\n",
      "Epoch [6/400], Loss: 0.1360\n",
      "\n",
      "Accuracy: 2578/2947 (87%)\n",
      "\n",
      "Epoch [7/400], Loss: 0.2414\n",
      "\n",
      "Accuracy: 2446/2947 (82%)\n",
      "\n",
      "Epoch [8/400], Loss: 0.1753\n",
      "\n",
      "Accuracy: 2582/2947 (87%)\n",
      "\n",
      "Epoch [9/400], Loss: 0.2921\n",
      "\n",
      "Accuracy: 2540/2947 (86%)\n",
      "\n",
      "Epoch [10/400], Loss: 0.3652\n",
      "\n",
      "Accuracy: 2597/2947 (88%)\n",
      "\n",
      "Epoch [11/400], Loss: 0.0282\n",
      "\n",
      "Accuracy: 2593/2947 (87%)\n",
      "\n",
      "Epoch [12/400], Loss: 0.1157\n",
      "\n",
      "Accuracy: 2542/2947 (86%)\n",
      "\n",
      "Epoch [13/400], Loss: 0.2574\n",
      "\n",
      "Accuracy: 2582/2947 (87%)\n",
      "\n",
      "Epoch [14/400], Loss: 0.0858\n",
      "\n",
      "Accuracy: 2645/2947 (89%)\n",
      "\n",
      "Epoch [15/400], Loss: 0.3640\n",
      "\n",
      "Accuracy: 2557/2947 (86%)\n",
      "\n",
      "Epoch [16/400], Loss: 0.0314\n",
      "\n",
      "Accuracy: 2648/2947 (89%)\n",
      "\n",
      "Epoch [17/400], Loss: 0.2683\n",
      "\n",
      "Accuracy: 2648/2947 (89%)\n",
      "\n",
      "Epoch [18/400], Loss: 0.3122\n",
      "\n",
      "Accuracy: 2599/2947 (88%)\n",
      "\n",
      "Epoch [19/400], Loss: 0.0765\n",
      "\n",
      "Accuracy: 2618/2947 (88%)\n",
      "\n",
      "Epoch [20/400], Loss: 0.1660\n",
      "\n",
      "Accuracy: 2632/2947 (89%)\n",
      "\n",
      "Epoch [21/400], Loss: 0.1142\n",
      "\n",
      "Accuracy: 2551/2947 (86%)\n",
      "\n",
      "Epoch [22/400], Loss: 0.1108\n",
      "\n",
      "Accuracy: 2581/2947 (87%)\n",
      "\n",
      "Epoch [23/400], Loss: 0.3686\n",
      "\n",
      "Accuracy: 2559/2947 (86%)\n",
      "\n",
      "Epoch [24/400], Loss: 0.1693\n",
      "\n",
      "Accuracy: 2532/2947 (85%)\n",
      "\n",
      "Epoch [25/400], Loss: 0.1398\n",
      "\n",
      "Accuracy: 2637/2947 (89%)\n",
      "\n",
      "Epoch [26/400], Loss: 0.1370\n",
      "\n",
      "Accuracy: 2586/2947 (87%)\n",
      "\n",
      "Epoch [27/400], Loss: 0.0686\n",
      "\n",
      "Accuracy: 2640/2947 (89%)\n",
      "\n",
      "Epoch [28/400], Loss: 0.1347\n",
      "\n",
      "Accuracy: 2611/2947 (88%)\n",
      "\n",
      "Epoch [29/400], Loss: 0.0531\n",
      "\n",
      "Accuracy: 2599/2947 (88%)\n",
      "\n",
      "Epoch [30/400], Loss: 0.0729\n",
      "\n",
      "Accuracy: 2599/2947 (88%)\n",
      "\n",
      "Epoch [31/400], Loss: 0.0850\n",
      "\n",
      "Accuracy: 2577/2947 (87%)\n",
      "\n",
      "Epoch [32/400], Loss: 0.0398\n",
      "\n",
      "Accuracy: 2632/2947 (89%)\n",
      "\n",
      "Epoch [33/400], Loss: 0.0854\n",
      "\n",
      "Accuracy: 2670/2947 (90%)\n",
      "\n",
      "Epoch [34/400], Loss: 0.0534\n",
      "\n",
      "Accuracy: 2663/2947 (90%)\n",
      "\n",
      "Epoch [35/400], Loss: 0.2501\n",
      "\n",
      "Accuracy: 2682/2947 (91%)\n",
      "\n",
      "Epoch [36/400], Loss: 0.0573\n",
      "\n",
      "Accuracy: 2662/2947 (90%)\n",
      "\n",
      "Epoch [37/400], Loss: 0.1768\n",
      "\n",
      "Accuracy: 2603/2947 (88%)\n",
      "\n",
      "Epoch [38/400], Loss: 0.1043\n",
      "\n",
      "Accuracy: 2617/2947 (88%)\n",
      "\n",
      "Epoch [39/400], Loss: 0.1729\n",
      "\n",
      "Accuracy: 2660/2947 (90%)\n",
      "\n",
      "Epoch [40/400], Loss: 0.0830\n",
      "\n",
      "Accuracy: 2570/2947 (87%)\n",
      "\n",
      "Epoch [41/400], Loss: 0.1003\n",
      "\n",
      "Accuracy: 2609/2947 (88%)\n",
      "\n",
      "Epoch [42/400], Loss: 0.0405\n",
      "\n",
      "Accuracy: 2555/2947 (86%)\n",
      "\n",
      "Epoch [43/400], Loss: 0.0708\n",
      "\n",
      "Accuracy: 2592/2947 (87%)\n",
      "\n",
      "Epoch [44/400], Loss: 0.0568\n",
      "\n",
      "Accuracy: 2600/2947 (88%)\n",
      "\n",
      "Epoch [45/400], Loss: 0.1043\n",
      "\n",
      "Accuracy: 2511/2947 (85%)\n",
      "\n",
      "Epoch [46/400], Loss: 0.0652\n",
      "\n",
      "Accuracy: 2654/2947 (90%)\n",
      "\n",
      "Epoch [47/400], Loss: 0.0743\n",
      "\n",
      "Accuracy: 2574/2947 (87%)\n",
      "\n",
      "Epoch [48/400], Loss: 0.0942\n",
      "\n",
      "Accuracy: 2588/2947 (87%)\n",
      "\n",
      "Epoch [49/400], Loss: 0.1227\n",
      "\n",
      "Accuracy: 2625/2947 (89%)\n",
      "\n",
      "Epoch [50/400], Loss: 0.0634\n",
      "\n",
      "Accuracy: 2657/2947 (90%)\n",
      "\n",
      "Epoch [51/400], Loss: 0.1025\n",
      "\n",
      "Accuracy: 2560/2947 (86%)\n",
      "\n",
      "Epoch [52/400], Loss: 0.0832\n",
      "\n",
      "Accuracy: 2612/2947 (88%)\n",
      "\n",
      "Epoch [53/400], Loss: 0.1080\n",
      "\n",
      "Accuracy: 2628/2947 (89%)\n",
      "\n",
      "Epoch [54/400], Loss: 0.1045\n",
      "\n",
      "Accuracy: 2558/2947 (86%)\n",
      "\n",
      "Epoch [55/400], Loss: 0.1362\n",
      "\n",
      "Accuracy: 2576/2947 (87%)\n",
      "\n",
      "Epoch [56/400], Loss: 0.2324\n",
      "\n",
      "Accuracy: 2613/2947 (88%)\n",
      "\n",
      "Epoch [57/400], Loss: 0.0461\n",
      "\n",
      "Accuracy: 2619/2947 (88%)\n",
      "\n",
      "Epoch [58/400], Loss: 0.0830\n",
      "\n",
      "Accuracy: 2667/2947 (90%)\n",
      "\n",
      "Epoch [59/400], Loss: 0.0458\n",
      "\n",
      "Accuracy: 2665/2947 (90%)\n",
      "\n",
      "Epoch [60/400], Loss: 0.2612\n",
      "\n",
      "Accuracy: 2664/2947 (90%)\n",
      "\n",
      "Epoch [61/400], Loss: 0.1291\n",
      "\n",
      "Accuracy: 2644/2947 (89%)\n",
      "\n",
      "Epoch [62/400], Loss: 0.1469\n",
      "\n",
      "Accuracy: 2620/2947 (88%)\n",
      "\n",
      "Epoch [63/400], Loss: 0.1309\n",
      "\n",
      "Accuracy: 2622/2947 (88%)\n",
      "\n",
      "Epoch [64/400], Loss: 0.1412\n",
      "\n",
      "Accuracy: 2669/2947 (90%)\n",
      "\n",
      "Epoch [65/400], Loss: 0.0683\n",
      "\n",
      "Accuracy: 2614/2947 (88%)\n",
      "\n",
      "Epoch [66/400], Loss: 0.0917\n",
      "\n",
      "Accuracy: 2665/2947 (90%)\n",
      "\n",
      "Epoch [67/400], Loss: 0.0375\n",
      "\n",
      "Accuracy: 2566/2947 (87%)\n",
      "\n",
      "Epoch [68/400], Loss: 0.2282\n",
      "\n",
      "Accuracy: 2498/2947 (84%)\n",
      "\n",
      "Epoch [69/400], Loss: 0.1408\n",
      "\n",
      "Accuracy: 2614/2947 (88%)\n",
      "\n",
      "Epoch [70/400], Loss: 0.2746\n",
      "\n",
      "Accuracy: 2451/2947 (83%)\n",
      "\n",
      "Epoch [71/400], Loss: 0.0313\n",
      "\n",
      "Accuracy: 2525/2947 (85%)\n",
      "\n",
      "Epoch [72/400], Loss: 0.1814\n",
      "\n",
      "Accuracy: 2684/2947 (91%)\n",
      "\n",
      "Epoch [73/400], Loss: 0.1021\n",
      "\n",
      "Accuracy: 2655/2947 (90%)\n",
      "\n",
      "Epoch [74/400], Loss: 0.0943\n",
      "\n",
      "Accuracy: 2642/2947 (89%)\n",
      "\n",
      "Epoch [75/400], Loss: 0.1670\n",
      "\n",
      "Accuracy: 2657/2947 (90%)\n",
      "\n",
      "Epoch [76/400], Loss: 0.3947\n",
      "\n",
      "Accuracy: 2560/2947 (86%)\n",
      "\n",
      "Epoch [77/400], Loss: 0.3582\n",
      "\n",
      "Accuracy: 2636/2947 (89%)\n",
      "\n",
      "Epoch [78/400], Loss: 0.1225\n",
      "\n",
      "Accuracy: 2659/2947 (90%)\n",
      "\n",
      "Epoch [79/400], Loss: 0.0541\n",
      "\n",
      "Accuracy: 2688/2947 (91%)\n",
      "\n",
      "Epoch [80/400], Loss: 0.0966\n",
      "\n",
      "Accuracy: 2663/2947 (90%)\n",
      "\n",
      "Epoch [81/400], Loss: 0.0781\n",
      "\n",
      "Accuracy: 2652/2947 (89%)\n",
      "\n",
      "Epoch [82/400], Loss: 0.7830\n",
      "\n",
      "Accuracy: 2615/2947 (88%)\n",
      "\n",
      "Epoch [83/400], Loss: 0.3547\n",
      "\n",
      "Accuracy: 2618/2947 (88%)\n",
      "\n",
      "Epoch [84/400], Loss: 0.0785\n",
      "\n",
      "Accuracy: 2645/2947 (89%)\n",
      "\n",
      "Epoch [85/400], Loss: 0.0219\n",
      "\n",
      "Accuracy: 2650/2947 (89%)\n",
      "\n",
      "Epoch [86/400], Loss: 0.0590\n",
      "\n",
      "Accuracy: 2645/2947 (89%)\n",
      "\n",
      "Epoch [87/400], Loss: 0.0941\n",
      "\n",
      "Accuracy: 2639/2947 (89%)\n",
      "\n",
      "Epoch [88/400], Loss: 0.1216\n",
      "\n",
      "Accuracy: 2577/2947 (87%)\n",
      "\n",
      "Epoch [89/400], Loss: 0.0516\n",
      "\n",
      "Accuracy: 2666/2947 (90%)\n",
      "\n",
      "Epoch [90/400], Loss: 0.1319\n",
      "\n",
      "Accuracy: 2630/2947 (89%)\n",
      "\n",
      "Epoch [91/400], Loss: 0.2021\n",
      "\n",
      "Accuracy: 2623/2947 (89%)\n",
      "\n",
      "Epoch [92/400], Loss: 0.1707\n",
      "\n",
      "Accuracy: 2676/2947 (90%)\n",
      "\n",
      "Epoch [93/400], Loss: 0.0959\n",
      "\n",
      "Accuracy: 2637/2947 (89%)\n",
      "\n",
      "Epoch [94/400], Loss: 0.0645\n",
      "\n",
      "Accuracy: 2663/2947 (90%)\n",
      "\n",
      "Epoch [95/400], Loss: 0.0215\n",
      "\n",
      "Accuracy: 2665/2947 (90%)\n",
      "\n",
      "Epoch [96/400], Loss: 0.0683\n",
      "\n",
      "Accuracy: 2660/2947 (90%)\n",
      "\n",
      "Epoch [97/400], Loss: 0.0350\n",
      "\n",
      "Accuracy: 2599/2947 (88%)\n",
      "\n",
      "Epoch [98/400], Loss: 0.1054\n",
      "\n",
      "Accuracy: 2627/2947 (89%)\n",
      "\n",
      "Epoch [99/400], Loss: 0.2196\n",
      "\n",
      "Accuracy: 2601/2947 (88%)\n",
      "\n",
      "Epoch [100/400], Loss: 0.1700\n",
      "\n",
      "Accuracy: 2531/2947 (85%)\n",
      "\n",
      "Epoch [101/400], Loss: 0.1239\n",
      "\n",
      "Accuracy: 2576/2947 (87%)\n",
      "\n",
      "Epoch [102/400], Loss: 0.1093\n",
      "\n",
      "Accuracy: 2581/2947 (87%)\n",
      "\n",
      "Epoch [103/400], Loss: 0.2220\n",
      "\n",
      "Accuracy: 2512/2947 (85%)\n",
      "\n",
      "Epoch [104/400], Loss: 0.1660\n",
      "\n",
      "Accuracy: 2645/2947 (89%)\n",
      "\n",
      "Epoch [105/400], Loss: 0.0824\n",
      "\n",
      "Accuracy: 2648/2947 (89%)\n",
      "\n",
      "Epoch [106/400], Loss: 0.1341\n",
      "\n",
      "Accuracy: 2642/2947 (89%)\n",
      "\n",
      "Epoch [107/400], Loss: 0.1050\n",
      "\n",
      "Accuracy: 2664/2947 (90%)\n",
      "\n",
      "Epoch [108/400], Loss: 0.0880\n",
      "\n",
      "Accuracy: 2640/2947 (89%)\n",
      "\n",
      "Epoch [109/400], Loss: 0.1420\n",
      "\n",
      "Accuracy: 2306/2947 (78%)\n",
      "\n",
      "Epoch [110/400], Loss: 0.1050\n",
      "\n",
      "Accuracy: 2577/2947 (87%)\n",
      "\n",
      "Epoch [111/400], Loss: 0.1303\n",
      "\n",
      "Accuracy: 2604/2947 (88%)\n",
      "\n",
      "Epoch [112/400], Loss: 0.1505\n",
      "\n",
      "Accuracy: 2562/2947 (86%)\n",
      "\n",
      "Epoch [113/400], Loss: 0.0866\n",
      "\n",
      "Accuracy: 2640/2947 (89%)\n",
      "\n",
      "Epoch [114/400], Loss: 0.2428\n",
      "\n",
      "Accuracy: 2588/2947 (87%)\n",
      "\n",
      "Epoch [115/400], Loss: 0.0476\n",
      "\n",
      "Accuracy: 2641/2947 (89%)\n",
      "\n",
      "Epoch [116/400], Loss: 0.0602\n",
      "\n",
      "Accuracy: 2663/2947 (90%)\n",
      "\n",
      "Epoch [117/400], Loss: 0.0479\n",
      "\n",
      "Accuracy: 2590/2947 (87%)\n",
      "\n",
      "Epoch [118/400], Loss: 0.1375\n",
      "\n",
      "Accuracy: 2623/2947 (89%)\n",
      "\n",
      "Epoch [119/400], Loss: 0.1554\n",
      "\n",
      "Accuracy: 2600/2947 (88%)\n",
      "\n",
      "Epoch [120/400], Loss: 0.0954\n",
      "\n",
      "Accuracy: 2618/2947 (88%)\n",
      "\n",
      "Epoch [121/400], Loss: 0.1264\n",
      "\n",
      "Accuracy: 2619/2947 (88%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuns\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-f10dda05a113>\", line 45, in <module>\n",
      "    train(loader_train, model, optimizer, loss_fn, device, epochs, epoch)\n",
      "  File \"<ipython-input-2-b14b96700c7d>\", line 65, in train\n",
      "    loss.backward() # 誤差を逆伝播させる\n",
      "  File \"C:\\Users\\shuns\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\", line 107, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"C:\\Users\\shuns\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 93, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuns\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuns\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\shuns\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\shuns\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\shuns\\Anaconda3\\lib\\inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\shuns\\Anaconda3\\lib\\inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\shuns\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\shuns\\Anaconda3\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\shuns\\Anaconda3\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\shuns\\Anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\shuns\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 1. GPUの設定（PyTorchでは明示的に指定する必要がある）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# 2. ハイパーパラメータの設定（最低限の設定）\n",
    "batch_size = 100\n",
    "num_classes = 6\n",
    "epochs = 100\n",
    "\n",
    "# 5. DataLoaderの作成\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 5-2. データのフォーマットを変換：PyTorchでの形式 = [画像数，チャネル数，高さ，幅]\n",
    "X_train = X_train.reshape(-1, 1, 3, 128)\n",
    "X_test = X_test.reshape(-1, 1, 3 ,128)\n",
    "\n",
    "# 5-3. PyTorchのテンソルに変換\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    " \n",
    "# 5-4. 入力(x)とラベル(y)を組み合わせて最終的なデータを作成\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "ds_test = TensorDataset(X_test, y_test)\n",
    " \n",
    "# 5-5. DataLoaderを作成\n",
    "loader_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(ds_test, batch_size=batch_size, shuffle=False)\n",
    " \n",
    "# 6. モデル作成\n",
    "model = CNN(num_classes=num_classes).to(device)\n",
    "print(model) # ネットワークの詳細を確認用に表示\n",
    " \n",
    "# 7. 損失関数を定義\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    " \n",
    "# 8. 最適化手法を定義（ここでは例としてAdamを選択）\n",
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    " \n",
    "# 9. 学習（エポック終了時点ごとにテスト用データで評価）\n",
    "print('Begin train')\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(loader_train, model, optimizer, loss_fn, device, epochs, epoch)\n",
    "    test(loader_test, model, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
