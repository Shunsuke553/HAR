{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\"トレーニングデータの読み込み\"\"\"\n",
    "# 長さ128(2.56sec)のトレーニングデータが7521件/21人分\n",
    "acc_x_train_df=pd.read_csv('./UCI HAR Dataset/train/Inertial Signals/total_acc_x_train.txt', header=None, sep='\\s+', na_values='na')\n",
    "acc_y_train_df=pd.read_csv('./UCI HAR Dataset/train/Inertial Signals/total_acc_y_train.txt', header=None, sep='\\s+', na_values='na')\n",
    "acc_z_train_df=pd.read_csv('./UCI HAR Dataset/train/Inertial Signals/total_acc_z_train.txt', header=None, sep='\\s+', na_values='na')\n",
    "\n",
    "# Dataframeからarrayへ変換\n",
    "acc_x_train=acc_x_train_df.values\n",
    "acc_y_train=acc_y_train_df.values\n",
    "acc_z_train=acc_z_train_df.values\n",
    "\n",
    "# 3軸を横に並べる\n",
    "X_train=np.c_[acc_x_train, acc_y_train, acc_z_train]\n",
    "\n",
    "# 正解ラベル\n",
    "    # 1 WALKING\n",
    "    # 2 WALKING_UPSTAIRS\n",
    "    # 3 WALKING_DOWNSTAIRS\n",
    "    # 4 SITTING\n",
    "    # 5 STANDING\n",
    "    # 6 LAYING\n",
    "train_label_df=pd.read_csv('./UCI HAR Dataset/train/Inertial Signals/y_train.txt', header=None, sep='\\s+', na_values='na')\n",
    "y_train=train_label_df.values.reshape(-1)\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "# 正解ラベルをone hot表現にする\n",
    "#ohe = OneHotEncoder()\n",
    "#y_train = ohe.fit_transform(train_label).A \n",
    "\n",
    "\"\"\"トレーニングデータの読み込み\"\"\"\n",
    "# 長さ128(2.56sec)のトレーニングデータが7521件/21人分\n",
    "acc_x_test_df=pd.read_csv('./UCI HAR Dataset/test/Inertial Signals/total_acc_x_test.txt', header=None, sep='\\s+', na_values='na')\n",
    "acc_y_test_df=pd.read_csv('./UCI HAR Dataset/test/Inertial Signals/total_acc_y_test.txt', header=None, sep='\\s+', na_values='na')\n",
    "acc_z_test_df=pd.read_csv('./UCI HAR Dataset/test/Inertial Signals/total_acc_z_test.txt', header=None, sep='\\s+', na_values='na')\n",
    "\n",
    "# Dataframeからarrayへ変換\n",
    "acc_x_test=acc_x_test_df.values\n",
    "acc_y_test=acc_y_test_df.values\n",
    "acc_z_test=acc_z_test_df.values\n",
    "\n",
    "# 3軸を横に並べる\n",
    "X_test=np.c_[acc_x_test, acc_y_test, acc_z_test]\n",
    "\n",
    "# 正解ラベル\n",
    "    # 1 WALKING\n",
    "    # 2 WALKING_UPSTAIRS\n",
    "    # 3 WALKING_DOWNSTAIRS\n",
    "    # 4 SITTING\n",
    "    # 5 STANDING\n",
    "    # 6 LAYING\n",
    "test_label_df=pd.read_csv('./UCI HAR Dataset/test/Inertial Signals/y_test.txt', header=None, sep='\\s+', na_values='na')\n",
    "y_test=test_label_df.values.reshape(-1)\n",
    "le = LabelEncoder()\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, \n",
    "                            batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, h0=None, l=None):\n",
    "        x, h = self.lstm(x, h0)\n",
    "        # 最後のステップのみ取り出す\n",
    "        x = x[:, -1, :]\n",
    "        # 取り出した最後のステップを線形層に入れる\n",
    "        x = self.linear(x)\n",
    "        # 余分な次元を削除する\n",
    "        # (batch_size, 1) -> (batch_size, )\n",
    "        x = x.squeeze()\n",
    "        return x\n",
    "\n",
    "# 学習用関数\n",
    "def train(loader_train, model_obj, optimizer, loss_fn, device, total_epoch, epoch):\n",
    "    \n",
    "    model_obj.train() # モデルを学習モードに変更\n",
    " \n",
    "    # ミニバッチごとに学習\n",
    "    for data, targets in loader_train:\n",
    " \n",
    "        data = data.to(device) # GPUを使用するため，to()で明示的に指定\n",
    "        targets = targets.to(device) # 同上\n",
    " \n",
    "        optimizer.zero_grad() # 勾配を初期化\n",
    "        outputs = model_obj(data) # 順伝播の計算\n",
    "        loss = loss_fn(outputs, targets) # 誤差を計算\n",
    "        loss.backward() # 誤差を逆伝播させる\n",
    "        optimizer.step() # 重みを更新する\n",
    "    \n",
    "    print ('Epoch [%d/%d], Loss: %.4f' % (epoch, total_epoch, loss.item()))\n",
    " \n",
    " \n",
    "# テスト用関数\n",
    "def test(loader_test, trained_model, device):\n",
    " \n",
    "    trained_model.eval() # モデルを推論モードに変更\n",
    "    correct = 0 # 正解率計算用の変数を宣言\n",
    " \n",
    "    # ミニバッチごとに推論\n",
    "    with torch.no_grad(): # 推論時には勾配は不要\n",
    "        for data, targets in loader_test:\n",
    " \n",
    "            data = data.to(device) #  GPUを使用するため，to()で明示的に指定\n",
    "            targets = targets.to(device) # 同上\n",
    " \n",
    "            outputs = trained_model(data) # 順伝播の計算\n",
    " \n",
    "            # 推論結果の取得と正誤判定\n",
    "            _, predicted = torch.max(outputs.data, 1) # 確率が最大のラベルを取得\n",
    "            correct += predicted.eq(targets.data.view_as(predicted)).sum() # 正解ならば正解数をカウントアップ\n",
    "    \n",
    "    # 正解率を計算\n",
    "    data_num = len(loader_test.dataset) # テストデータの総数\n",
    "    print('\\nAccuracy: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "LSTM(\n",
      "  (lstm): LSTM(3, 64, num_layers=2, batch_first=True)\n",
      "  (linear): Linear(in_features=64, out_features=6, bias=True)\n",
      ")\n",
      "Begin train\n",
      "Epoch [1/500], Loss: 1.7940\n",
      "\n",
      "Accuracy: 1000/2947 (33%)\n",
      "\n",
      "Epoch [2/500], Loss: 1.7720\n",
      "\n",
      "Accuracy: 1026/2947 (34%)\n",
      "\n",
      "Epoch [3/500], Loss: 1.7318\n",
      "\n",
      "Accuracy: 1026/2947 (34%)\n",
      "\n",
      "Epoch [4/500], Loss: 1.5675\n",
      "\n",
      "Accuracy: 1026/2947 (34%)\n",
      "\n",
      "Epoch [5/500], Loss: 1.4210\n",
      "\n",
      "Accuracy: 1026/2947 (34%)\n",
      "\n",
      "Epoch [6/500], Loss: 1.4278\n",
      "\n",
      "Accuracy: 990/2947 (33%)\n",
      "\n",
      "Epoch [7/500], Loss: 1.3849\n",
      "\n",
      "Accuracy: 1006/2947 (34%)\n",
      "\n",
      "Epoch [8/500], Loss: 1.3765\n",
      "\n",
      "Accuracy: 959/2947 (32%)\n",
      "\n",
      "Epoch [9/500], Loss: 1.3739\n",
      "\n",
      "Accuracy: 959/2947 (32%)\n",
      "\n",
      "Epoch [10/500], Loss: 1.3682\n",
      "\n",
      "Accuracy: 959/2947 (32%)\n",
      "\n",
      "Epoch [11/500], Loss: 1.3634\n",
      "\n",
      "Accuracy: 1026/2947 (34%)\n",
      "\n",
      "Epoch [12/500], Loss: 1.3582\n",
      "\n",
      "Accuracy: 1000/2947 (33%)\n",
      "\n",
      "Epoch [13/500], Loss: 1.3590\n",
      "\n",
      "Accuracy: 1000/2947 (33%)\n",
      "\n",
      "Epoch [14/500], Loss: 1.3555\n",
      "\n",
      "Accuracy: 1000/2947 (33%)\n",
      "\n",
      "Epoch [15/500], Loss: 1.3505\n",
      "\n",
      "Accuracy: 1115/2947 (37%)\n",
      "\n",
      "Epoch [16/500], Loss: 1.3494\n",
      "\n",
      "Accuracy: 1274/2947 (43%)\n",
      "\n",
      "Epoch [17/500], Loss: 1.3491\n",
      "\n",
      "Accuracy: 1243/2947 (42%)\n",
      "\n",
      "Epoch [18/500], Loss: 1.3461\n",
      "\n",
      "Accuracy: 1177/2947 (39%)\n",
      "\n",
      "Epoch [19/500], Loss: 1.3380\n",
      "\n",
      "Accuracy: 1053/2947 (35%)\n",
      "\n",
      "Epoch [20/500], Loss: 1.3257\n",
      "\n",
      "Accuracy: 1160/2947 (39%)\n",
      "\n",
      "Epoch [21/500], Loss: 1.3164\n",
      "\n",
      "Accuracy: 1118/2947 (37%)\n",
      "\n",
      "Epoch [22/500], Loss: 1.3223\n",
      "\n",
      "Accuracy: 1317/2947 (44%)\n",
      "\n",
      "Epoch [23/500], Loss: 1.2761\n",
      "\n",
      "Accuracy: 1108/2947 (37%)\n",
      "\n",
      "Epoch [24/500], Loss: 1.3182\n",
      "\n",
      "Accuracy: 1184/2947 (40%)\n",
      "\n",
      "Epoch [25/500], Loss: 1.2894\n",
      "\n",
      "Accuracy: 1273/2947 (43%)\n",
      "\n",
      "Epoch [26/500], Loss: 1.2106\n",
      "\n",
      "Accuracy: 983/2947 (33%)\n",
      "\n",
      "Epoch [27/500], Loss: 1.5080\n",
      "\n",
      "Accuracy: 967/2947 (32%)\n",
      "\n",
      "Epoch [28/500], Loss: 1.5004\n",
      "\n",
      "Accuracy: 1191/2947 (40%)\n",
      "\n",
      "Epoch [29/500], Loss: 1.2514\n",
      "\n",
      "Accuracy: 1207/2947 (40%)\n",
      "\n",
      "Epoch [30/500], Loss: 1.2593\n",
      "\n",
      "Accuracy: 1117/2947 (37%)\n",
      "\n",
      "Epoch [31/500], Loss: 1.3821\n",
      "\n",
      "Accuracy: 1058/2947 (35%)\n",
      "\n",
      "Epoch [32/500], Loss: 1.4182\n",
      "\n",
      "Accuracy: 1109/2947 (37%)\n",
      "\n",
      "Epoch [33/500], Loss: 1.4153\n",
      "\n",
      "Accuracy: 1088/2947 (36%)\n",
      "\n",
      "Epoch [34/500], Loss: 1.3930\n",
      "\n",
      "Accuracy: 1094/2947 (37%)\n",
      "\n",
      "Epoch [35/500], Loss: 1.3691\n",
      "\n",
      "Accuracy: 1175/2947 (39%)\n",
      "\n",
      "Epoch [36/500], Loss: 1.3308\n",
      "\n",
      "Accuracy: 1179/2947 (40%)\n",
      "\n",
      "Epoch [37/500], Loss: 1.3200\n",
      "\n",
      "Accuracy: 1265/2947 (42%)\n",
      "\n",
      "Epoch [38/500], Loss: 1.3104\n",
      "\n",
      "Accuracy: 967/2947 (32%)\n",
      "\n",
      "Epoch [39/500], Loss: 1.3402\n",
      "\n",
      "Accuracy: 968/2947 (32%)\n",
      "\n",
      "Epoch [40/500], Loss: 1.3517\n",
      "\n",
      "Accuracy: 1008/2947 (34%)\n",
      "\n",
      "Epoch [41/500], Loss: 1.3111\n",
      "\n",
      "Accuracy: 1268/2947 (43%)\n",
      "\n",
      "Epoch [42/500], Loss: 1.2825\n",
      "\n",
      "Accuracy: 1290/2947 (43%)\n",
      "\n",
      "Epoch [43/500], Loss: 1.2613\n",
      "\n",
      "Accuracy: 1279/2947 (43%)\n",
      "\n",
      "Epoch [44/500], Loss: 1.2742\n",
      "\n",
      "Accuracy: 1267/2947 (42%)\n",
      "\n",
      "Epoch [45/500], Loss: 1.2327\n",
      "\n",
      "Accuracy: 1269/2947 (43%)\n",
      "\n",
      "Epoch [46/500], Loss: 1.2482\n",
      "\n",
      "Accuracy: 1296/2947 (43%)\n",
      "\n",
      "Epoch [47/500], Loss: 1.1989\n",
      "\n",
      "Accuracy: 1082/2947 (36%)\n",
      "\n",
      "Epoch [48/500], Loss: 1.3315\n",
      "\n",
      "Accuracy: 1198/2947 (40%)\n",
      "\n",
      "Epoch [49/500], Loss: 1.4067\n",
      "\n",
      "Accuracy: 1177/2947 (39%)\n",
      "\n",
      "Epoch [50/500], Loss: 1.3107\n",
      "\n",
      "Accuracy: 1249/2947 (42%)\n",
      "\n",
      "Epoch [51/500], Loss: 1.2502\n",
      "\n",
      "Accuracy: 1611/2947 (54%)\n",
      "\n",
      "Epoch [52/500], Loss: 1.1651\n",
      "\n",
      "Accuracy: 1426/2947 (48%)\n",
      "\n",
      "Epoch [53/500], Loss: 1.1962\n",
      "\n",
      "Accuracy: 1206/2947 (40%)\n",
      "\n",
      "Epoch [54/500], Loss: 1.2407\n",
      "\n",
      "Accuracy: 1125/2947 (38%)\n",
      "\n",
      "Epoch [55/500], Loss: 1.2760\n",
      "\n",
      "Accuracy: 1087/2947 (36%)\n",
      "\n",
      "Epoch [56/500], Loss: 1.2827\n",
      "\n",
      "Accuracy: 1066/2947 (36%)\n",
      "\n",
      "Epoch [57/500], Loss: 1.2654\n",
      "\n",
      "Accuracy: 1077/2947 (36%)\n",
      "\n",
      "Epoch [58/500], Loss: 1.2511\n",
      "\n",
      "Accuracy: 1060/2947 (35%)\n",
      "\n",
      "Epoch [59/500], Loss: 1.2538\n",
      "\n",
      "Accuracy: 1116/2947 (37%)\n",
      "\n",
      "Epoch [60/500], Loss: 1.2712\n",
      "\n",
      "Accuracy: 1130/2947 (38%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. GPUの設定（PyTorchでは明示的に指定する必要がある）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# 2. ハイパーパラメータの設定（最低限の設定）\n",
    "batch_size = len(y_train)\n",
    "num_classes = 6\n",
    "epochs = 500\n",
    "\n",
    "# 5-2. データのフォーマットを変換：PyTorchでの形式 = [batch size，seq len，input size]\n",
    "X_train = X_train.reshape(-1, 3, 128).transpose((0,2,1))\n",
    "X_test = X_test.reshape(-1, 3, 128).transpose((0,2,1))\n",
    "\n",
    "# 5-3. PyTorchのテンソルに変換\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    " \n",
    "# 5-4. 入力(x)とラベル(y)を組み合わせて最終的なデータを作成\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "ds_test = TensorDataset(X_test, y_test)\n",
    " \n",
    "# 5-5. DataLoaderを作成\n",
    "loader_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(ds_test, batch_size=batch_size, shuffle=False)\n",
    " \n",
    "# 6. モデル作成\n",
    "model = LSTM(input_size=3, \n",
    "             hidden_size=64, \n",
    "             output_size=num_classes, \n",
    "             num_layers=2)\n",
    "model.to(device)\n",
    "print(model) # ネットワークの詳細を確認用に表示\n",
    " \n",
    "# 7. 損失関数を定義\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    " \n",
    "# 8. 最適化手法を定義（ここでは例としてAdamを選択）\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    " \n",
    "# 9. 学習（エポック終了時点ごとにテスト用データで評価）\n",
    "print('Begin train')\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(loader_train, model, optimizer, loss_fn, device, epochs, epoch)\n",
    "    test(loader_test, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
